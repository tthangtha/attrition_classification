---
title: "waf22"
author: "Thanyaphorn Thangthanakul"
date: "9/27/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# WAF Data Challenge: IBM HR data

## EDA: Who are the employees?
The given data has 1470 rows for each employee and 35 columns decribing their attributes, which includes age, gender, department, education, job level, job involvement, etc. 

The categorical attributes include: 'Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime'

And the numberical attributes include: 'Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager'
       
Summary information about the employees:

![Distribution of employees' age](agedist.png){width=250px}

The age of employees is close to normally distributed with median age around 35. Most of the employees are in the age range from 25 to 45.

![Distribution of employees' gender](fmdist.png){width=250px}
There are more male than female employees, with 60% male and 40% female.

![Distribution of employees' distance from home](distdist.png){width=250px}


Many employees live very close to their workplace, with around 28% living 1-2 distance units from home and the majority of the employees living within 10 distance units.

![Distribution of employees' department](depdist.png){width=250px}

![Distribution of employees' department](depjobs.png){width=400px}


The majority of employees, 65.4%, work in the Research & Development department. Followed by the Sales department at 30.3%. Then, the HR department has 4.3% of employees. For job roles, sales executive is the most popular role and is the majority of role in Sales department. The second and third most popular role are research scientist and laboratory technician within the R&D department.

These data contains employees who left the company and also those who stay. Around 83.8% of employees left the company, while 16.1% stay with IBM. We can see that the dataset is imbalanced.

Employee attrition can be related to many factors. I will explore some of them with significant implications here.

![Employee Attrition](attrition.png){width=250px} 


Attrition with respect to other attributes: 
![Employee attrition with respect to Age](attri_age.png){width=400px} 

![Employee attrition with respect to Age](attri_age.png){width=400px}

![Employee attrition with respect to Environment Satisfaction](environs.png){width=400px}
![Employee attrition with respect to Job Level](joblevel_attri.png){width=400px}
![Employee attrition with respect to Monthly Income](monthinc.png){width=400px}
![Employee attrition with respect to Years at Company](yearsatcom.png){width=400px}


Some observations are that attrition rate is higher for younger employees. Surprisingly, employees with low environment satisfaction still stays with the job. Employees with low job level, low income, and less number of years at the company tend to have high attrition.

## Model to forecast attrition
First, I made Attrition numerical by replacing Yes with 1 and No with 0. From looking into the data, I could see that EmployeeCount and StandardHours are the same across all the employees, and EmployeeNumber is just the order of the employees. These columns should not be used in the model.

```{r echo=FALSE, out.width="100%", fig.align='center'}
knitr::include_graphics("heatmap.png")
```

![Heatmap](heatmap.png){width=600px}
First of all, there might be many columns that are correlated. There is very high correlation between JobLevel & MonthlyIncome, at 95%. There are also significant correlation between PerformanceRating & PercentSalaryHike, JobLevel & TotalWorkingYears, YearsWithCurrentManager & YearsAtCompany. All these correlations make sense when I think of it. Still, to reduce collinearity, I choose to only exclude JobLevel from the model because I believe it is represented in MonthlyIncome, which represents more information. To fit a model, I do one-hot encoding for the categorical variables. I first tried to fit a simple logistic regression to the training data.

![Simple Logistic Regression Model Summary](simplelr.png){width=300px}

The model has a high accuracy of 85%, but consider that the precision for Attrition 1 is very low and the recall is quite low as well, and this is also reflected in the low f1-score.
As I mentioned above, the dataset is imbalanced as there is 83.8% of 0 and 16.1% of 1 for Attrition. It is important to note that the high accuracy may be very misleading. If the model just always predict 0s, then the accuracy of this model is already 83.8%. So, I look into the confusion matrix and calculate precision and recall for each model.

Resampling is a common way to tackle the problem. Here, I choose to use over-sampling, which is adding instances from the under-represented class (1) sampled with replacement. I think over-sampling is better for this case because I do not have a lot of data and would like to keep all the useful information in the instances with Attrition 0s. I fitted the over-sampled data using 3 models: Logistic Regression, Decision Tree, and Random Forest.

![Logistic Regression with Over-Sampling Summary](lr_overs.png){width=300px}

![Decision Tree with Over-Sampling Summary](dt_over.png){width=300px}

![Random Forest with Over-Sampling Summary](rf_over.png){width=300px}

The over-sampled logistic regression model has a slightly lower accuracy than the simple model, but it has a significantly higher precision and recall for Attrition of 1. The decision tree and random forest models give higer accuracy, precision, and recall, with the random forest model giving the best scores. Furthermore, I analyzed the coefficients from the logistic regression model and their significance. Some significant negative coefficients are education field, being married, job involvement, etc. And some positive coefficients are doing overtimes, age, mumber of companies they've worked at, performance rating, and percent of salary hike.

The HR team could use these model to predict attrition of the employees, and devise future plans to hire more people in certain roles. Or, the team can learn useful information from the characteristics of employees with attrition and the significance of each factor in determining the attrition in the model, so they could develop plans to incentivize employees in the aspects that would make them stay with IBM or know what to look for in hiring people for certain roles.
